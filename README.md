# Gesture Controlled Electronics

A cutting-edge system that empowers users to control electronic devices through natural hand gestures. This project harnesses the capabilities of Raspberry Pi 4B, Python libraries (Mediapipe, OpenCV, OS), and a 4-channel relay module to recognize gestures and trigger actions on connected devices.

## 📜 Overview
This project aims to:

- Develop a gesture-controlled interface for seamless interaction with electronics.
- Recognize hand gestures using a camera and computer vision techniques.
- Control devices like LEDs, motors, and other appliances via GPIO pins on the Raspberry Pi.
- Demonstrate an intuitive human-computer interaction system for smart automation.

## 🏗️ Hardware Components
- Raspberry Pi 4B – the core computing unit.
- 5-Megapixel Camera – captures hand gestures in real-time.
- 4-Channel Relay Module – interfaces to control external devices.
- Jumper Wires and Breadboard – for hardware connections.
- Electronic Devices – e.g., LEDs, DC motors, servos.

## 🧠 Software Requirements
- Raspbian OS (for Raspberry Pi)
- Python 3.x
- Mediapipe – for hand landmark detection.
- OpenCV – for image processing.
- OS module – for system integration.

## 🔥 Key Features
- Real-time gesture recognition using camera input.
- Landmark detection and analysis with Mediapipe.
- Custom gesture-action mapping (e.g., turning on/off devices).
- Integration with 4-channel relay for controlling multiple electronics.
- User-friendly and accessible design with scope for UI enhancements.

## 📝 Methodology
- Hardware Setup – Connect Raspberry Pi, camera, and relay module.
- Software Installation – Install necessary libraries and set up the environment.
- Gesture Recognition – Capture hand landmarks and recognize gestures.
- Gesture-to-Action Mapping – Define specific actions for gestures (e.g., "swag" gesture to turn on a motor).
- Relay Control – Trigger GPIO pins to control electronic devices.
- Testing and Refinement – Ensure robustness and accuracy.
- Optional UI – Add feedback or calibration interface.
- Documentation – Comprehensive documentation for replication and deployment.

## Phenomena Used

![Phenomena](https://github.com/saaranshg/Hand-Gestures-Controlled-Electronics/blob/main/phenomena_used.jpg?raw=true "Phenomena")



## 🚀 Results
- Successfully controlled devices (LEDs, motors) with recognized hand gestures.
- Achieved real-time processing with minimal latency.
- Built a prototype showcasing intuitive control over multiple devices.

## Prototype and Circuit

![Circuit](https://github.com/saaranshg/Hand-Gestures-Controlled-Electronics/blob/main/top_view_final_prototype.jpg?raw=true "Circuit")

![Prototype](https://github.com/saaranshg/Hand-Gestures-Controlled-Electronics/blob/main/right_view.jpg?raw=true "Prototype")

## 🔮 Future Scope
- Advanced Gesture Recognition – Integrate ML models for complex gestures.
- Multi-Device Integration – Expand to home automation and IoT devices.
- User-Defined Gestures – Personalize actions with custom gestures.
- Enhanced UI/UX – Develop GUI or mobile apps for configuration.
- Gesture-Controlled Robotics – Extend control to robotic systems.
- Integration with Virtual Assistants – Combine gestures with voice commands.

## 📽️ Demo Video
🎥 [Watch the Project in Action](https://drive.google.com/file/d/1KIPo2Miq5ARKIxDaN3zBw7H7Isqe0QFF/view?usp=sharing)
